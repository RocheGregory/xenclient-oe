diff --git a/arch/x86/xen/enlighten.c b/arch/x86/xen/enlighten.c
index fac5e4f..40ede8a 100644
--- a/arch/x86/xen/enlighten.c
+++ b/arch/x86/xen/enlighten.c
@@ -1562,10 +1562,13 @@ asmlinkage __visible void __init xen_start_kernel(void)
 	/* Prevent unwanted bits from being set in PTEs. */
 	__supported_pte_mask &= ~_PAGE_GLOBAL;
 #if 0
+	/*
+	 * Re-enabling the PAT.
+	 * UIVM can change cache-attributes for xenfb2.
+	 */
 	if (!xen_initial_domain())
-#endif
 		__supported_pte_mask &= ~(_PAGE_PWT | _PAGE_PCD);
-
+#endif
 	/*
 	 * Prevent page tables from being allocated in highmem, even
 	 * if CONFIG_HIGHPTE is enabled.
@@ -1619,12 +1622,18 @@ asmlinkage __visible void __init xen_start_kernel(void)
 	acpi_numa = -1;
 #endif
 #ifdef CONFIG_X86_PAT
+# if 0
+	/*
+	 * Do not disable it, we backported Konrad patches to have it.
+	 * Required for Xenfb2's caching policy (otherwise igfx has trouble)
+	 */
 	/*
 	 * For right now disable the PAT. We should remove this once
 	 * git commit 8eaffa67b43e99ae581622c5133e20b0f48bcef1
 	 * (xen/pat: Disable PAT support for now) is reverted.
 	 */
 	pat_enabled = 0;
+# endif
 #endif
 	/* Don't do the full vcpu_info placement stuff until we have a
 	   possible map and a non-dummy shared_info. */
diff --git a/arch/x86/xen/mmu.c b/arch/x86/xen/mmu.c
index a8a1a3d..80c176d 100644
--- a/arch/x86/xen/mmu.c
+++ b/arch/x86/xen/mmu.c
@@ -410,13 +410,13 @@ static pteval_t pte_pfn_to_mfn(pteval_t val)
 __visible pteval_t xen_pte_val(pte_t pte)
 {
 	pteval_t pteval = pte.pte;
-#if 0
+
 	/* If this is a WC pte, convert back from Xen WC to Linux WC */
 	if ((pteval & (_PAGE_PAT | _PAGE_PCD | _PAGE_PWT)) == _PAGE_PAT) {
 		WARN_ON(!pat_enabled);
 		pteval = (pteval & ~_PAGE_PAT) | _PAGE_PWT;
 	}
-#endif
+
 	return pte_mfn_to_pfn(pteval);
 }
 PV_CALLEE_SAVE_REGS_THUNK(xen_pte_val);
@@ -454,7 +454,7 @@ void xen_set_pat(u64 pat)
 
 __visible pte_t xen_make_pte(pteval_t pte)
 {
-#if 0
+
 	/* If Linux is trying to set a WC pte, then map to the Xen WC.
 	 * If _PAGE_PAT is set, then it probably means it is really
 	 * _PAGE_PSE, so avoid fiddling with the PAT mapping and hope
@@ -467,7 +467,7 @@ __visible pte_t xen_make_pte(pteval_t pte)
 		if ((pte & (_PAGE_PCD | _PAGE_PWT)) == _PAGE_PWT)
 			pte = (pte & ~(_PAGE_PCD | _PAGE_PWT)) | _PAGE_PAT;
 	}
-#endif
+
 	pte = pte_pfn_to_mfn(pte);
 
 	return native_make_pte(pte);
diff --git a/mm/memory.c b/mm/memory.c
index baf1ef4..e749570 100644
--- a/mm/memory.c
+++ b/mm/memory.c
@@ -782,6 +782,8 @@ struct page *vm_normal_page(struct vm_area_struct *vma, unsigned long addr,
 check_pfn:
 	if (unlikely(pfn > highest_memmap_pfn)) {
 		print_bad_pte(vma, addr, pte, NULL);
+                printk(KERN_ALERT "pfn:%#lx > highest_memmap_pfn:%#lx\n",
+		       pfn, highest_memmap_pfn);
 		return NULL;
 	}
 
